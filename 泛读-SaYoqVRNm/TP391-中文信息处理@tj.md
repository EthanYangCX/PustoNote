# 随堂笔记

## 第一周 0305

- 传统方法和深度学习结合。传统方法依然值得借鉴，深度学习囫囵吞枣，问题也不去分析，这样不妥。
- 发展历史
    - 上世纪60年代计算能力太差，关键字匹配为主，70年代语法语义分析，80年开始繁荣，实用化、工程化，2018年BERT大幅提升，更多人对NLP感兴趣
    - 基于统计的方法，也是随着硬件提升，因为需要语料库，需要有计算能力
    - ELIZA
    - 中文信息处理80年代起步，是因为几大障碍：1、输入，2、分词，3、句法分析（仍然困难）
        - 92年分词标准
        - 知网一开始是
        - 人日语料库也很重要
        - `sig`：特殊兴趣小组
- 应用领域
    - 信息检索领域，微软为bing开研究院研究中文检索
    - QA，闲聊还是特定领域开发时更困难？
- 发展趋势
    - 深度学习好，但资源占用高，对于本模块资源少，或者语料少时，还是需要传统方法发挥作用。
    - 基础领域已经有规范，但问答、摘要等，答案很有主观性的领域，还需要评价规范
- 课程安排
    - 课程目的
        - 主题都明白，而且很多知识都能用得到
    - 课程安排
        - 词法は分词、语法は词性标注（别的不太成熟，作为课程就不讲了）、语义分析跟语法分析是并列的是因为很多时候直接依靠词法（课上不大讲），2/3都是讲应用领域的内容
- 相关拓展
    - 语言处理可以用文本的后处理来提升质量
    - 时间接洽的话可以用比赛当大作业
- 第二章 自动分词（传统方法）
    - 要了解规范，知道自己的算法有没有错
    - 不用词典只用语料库的为主流
    - 机械分词（基于词典的）
        - 分词词典
        - 以后作业不用这个方法可能用不到这方面知识
        - 正/逆向最大匹配
            - 问题：为什么要设计正向、逆向、最大、最小的算法？为什么这么多种？
                - *我觉，最小匹配快，但会把长词组切碎；逆向比较适合常见的定中结构的名词*
            - 歧义的解决方法之一，正逆向分词的结果不同是判断依据之一