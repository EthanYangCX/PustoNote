# 随堂笔记

## 第一周 0304

- 第二讲。
- 回归问题、分类问题
- 无监督、有监督
- 先讨论回归，线性回归。样本数m，输入x，输出目标变量t，hypothesis（假设），基本概念需要强调一下，cost func 用 mean square error，损失函数之变量为ω
- 前面三四次课都是吴恩达机器学习，后面才进入斯坦福231、224。自己看完吴恩达也需要大概十几个小时。
- 为什么深度学习都依赖梯度下降，因为有一个假设，要这杨在损失函数上找最优的值
- 线性回归，两个ω，损失函数是二维抛物面。等高线表示之亦可。
- 线性回归唯一零点
- 课下作业有要实现锑度下降的，要记得更新同步（用temp）
- 实际问题
    - 全局局部最小
    - 可以一次所有导数都更新，也可以一次取一部分的（SGD, stochastic），为了计算量
    - 学习率、收敛
- n个特征，于是x的下标j表示第几个特征，上标i表示第几个样本，回归也是多元了。自$x_1$始，因为$ω_0$为偏移量
- practical issues
    - 特征scaling
        - 你看用等高线，圆形，收敛一直一个方向，椭圆，则你画个垂线很容易超调
    - mean normalization：很简单的正则化操作，减去平均，除以方差
    - 制造新的输入，然后继续用线性回归，这一步叫特征工程，传统机器学习之特征工程很重要，思考你用平方、立方、相乘还是对数之类的。深度学习不需要，但这个工作原理要懂
- 最小二乘法。Normal Equation。唯一解故直接求解可（最小二乘法的矩阵算）。
    - 问题：为什么我们不用它呢？
        - *因为复杂情形不能用之？大规模了逆矩阵难求？*
        - 对，矩阵计算总不是线性的，且空间也大，数据都放不进去那GPU也无法加速。样本有超级大。
- 对数几率回归（logistic），叫回归实则分类
    - 不用线性回归取阈值的方法，线性会被x取值不均匀的样本拉得很偏，比如被大值很低
    - g(z)=1/(1+e-z)，z叫logit
    - 例如z是ωx，ω0为负让图像右移，ω1很小让图像扁平
    - 分界线就是z=0
    - 二维逻辑回归就是一条线为分界线（使z=0，级$ω^T x = 0$）
    - 非线性的话。比如决策边界是决策边界。比如把logit z 变成x1^2+x2^2-1 就是个圆
        - 还是特征工程
        - 线性回归有很多统计工具帮助找，但分类问题没有那么多工具可以用
- 编程的各位，建议mac或至少linux，体验比win好太多って，虚拟机也可以；虚拟机有自己的问题
- 晚上是上机课，会讲基本python用法，安装包，实现线性回归，作业就是实现线性、对数几率

## 晚课

- anaconda 比较方便包管理。https://blog.csdn.net/ITLearnHall/article/details/81708148，或者直接官网搜，基本就一直「下一步」
- 用 anaconda navigator 里面的 jupyterLab
- 类型
    - f-string，里面可以用花括号括起来变量，里面还能格式化
        - f'{a:.4f}'
        - 比.format写着舒服
- List
    - 里面啥都能放，append（插元素）, extend（另一个表接过去）, pop（把最后一个元素）
    - .index()，找出现的位置
- slicing of lists
    - 左闭右开，第三个参数是步长
    - sorted
    - for ind, ele in enumerate(l):
- list comprehensions 列表推导
    - squares = [x ** 2 for x in nums if x % 2 == 0]
- dict
    - in 返回是否在d里
    - .get() 欲取值，不存在则用自己指定的默认值
    - del d['fish'] 用关键词直接删
    - d.items() 枚举
- dict comprehensions
- set
    - set(l)
    - 大括号
- tuple
    - 小括号
    - 不能改，所以可哈希，所以可以作为词典的键
        - 列表不可哈希（unhashable type），就是列表的成员能变掉，这就没办法当索引
- 函数
    - def
- 类
    - class X(object):
- basic of numpy
    - .array()
    - .shape
    - a[0,0] 以索引
        - 索引时，切片会切出来比如一行四列矩阵，不切片则会返回向量而非矩阵，后者可能出bug
    - zeros, ones, full, eye, 
    - `?np.full` JupyterLabを使用时可用，帮助，`??`返回源码
    - bool indexing
        - `a[a>2]`
    - reshape，形状里面写一个-1可以自动推导
    - dtype（比如=float64，reshape时就能用）
    - math
        - 矩阵+-*/，逐元素
        - .dot()
        - @ 表示点乘
        - mean, sum, np.sum(a, axis=0)，axis表示沿着那个维度算
    - broadcasting
- PIL for image processing
- 一般上课到八点